{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tan4BMclb1hs"
      },
      "source": [
        "# Yoruba TTS Training on Google Colab\n",
        "\n",
        "This notebook sets up and trains a VITS-based Text-to-Speech model for Yoruba language.\n",
        "\n",
        "**Features:**\n",
        "- GPU-accelerated training\n",
        "- Automatic setup and dependency installation\n",
        "- Training progress monitoring\n",
        "- Audio synthesis testing\n",
        "\n",
        "**Note:** Make sure to enable GPU runtime: `Runtime > Change runtime type > GPU`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uD1eijz5b1hu"
      },
      "source": [
        "## 1. Setup Environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "hO1oQNl5b1hv",
        "outputId": "a50a3e56-abd3-45f7-b9a0-d00d4b001ce6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Nov 29 16:26:18 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   69C    P8             11W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "# Check GPU availability\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QyNFWIMJb1hv",
        "outputId": "1b794ad1-f577-41e3-b990-9d60af7fad3a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Naija_tts'...\n",
            "remote: Enumerating objects: 28, done.\u001b[K\n",
            "remote: Counting objects: 100% (28/28), done.\u001b[K\n",
            "remote: Compressing objects: 100% (20/20), done.\u001b[K\n",
            "remote: Total 28 (delta 5), reused 28 (delta 5), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (28/28), 120.69 KiB | 13.41 MiB/s, done.\n",
            "Resolving deltas: 100% (5/5), done.\n",
            "/content/Naija_tts\n"
          ]
        }
      ],
      "source": [
        "# Clone the repository\n",
        "!git clone https://github.com/T-ultrafast/Naija_tts.git\n",
        "%cd Naija_tts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "BiqoyPHUb1hw",
        "outputId": "4a215beb-fc3c-4ce1-9894-fc8c3693ce69",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.12/dist-packages (24.1.2)\n",
            "Collecting pip\n",
            "  Downloading pip-25.3-py3-none-any.whl.metadata (4.7 kB)\n",
            "Downloading pip-25.3-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m30.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 24.1.2\n",
            "    Uninstalling pip-24.1.2:\n",
            "      Successfully uninstalled pip-24.1.2\n",
            "Successfully installed pip-25.3\n",
            "\u001b[31mERROR: Ignored the following versions that require a different python version: 0.0.10.2 Requires-Python >=3.6.0,<3.9; 0.0.10.3 Requires-Python >=3.6.0,<3.9; 0.0.11 Requires-Python >=3.6.0,<3.9; 0.0.12 Requires-Python >=3.6.0,<3.9; 0.0.13.1 Requires-Python >=3.6.0,<3.9; 0.0.13.2 Requires-Python >=3.6.0,<3.9; 0.0.14.1 Requires-Python >=3.6.0,<3.9; 0.0.15 Requires-Python >=3.6.0,<3.9; 0.0.15.1 Requires-Python >=3.6.0,<3.9; 0.0.9 Requires-Python >=3.6.0,<3.9; 0.0.9.1 Requires-Python >=3.6.0,<3.9; 0.0.9.2 Requires-Python >=3.6.0,<3.9; 0.0.9a10 Requires-Python >=3.6.0,<3.9; 0.0.9a9 Requires-Python >=3.6.0,<3.9; 0.1.0 Requires-Python >=3.6.0,<3.10; 0.1.1 Requires-Python >=3.6.0,<3.10; 0.1.2 Requires-Python >=3.6.0,<3.10; 0.1.3 Requires-Python >=3.6.0,<3.10; 0.10.0 Requires-Python >=3.7.0,<3.11; 0.10.1 Requires-Python >=3.7.0,<3.11; 0.10.2 Requires-Python >=3.7.0,<3.11; 0.11.0 Requires-Python >=3.7.0,<3.11; 0.11.1 Requires-Python >=3.7.0,<3.11; 0.12.0 Requires-Python >=3.7.0,<3.11; 0.13.0 Requires-Python >=3.7.0,<3.11; 0.13.1 Requires-Python >=3.7.0,<3.11; 0.13.2 Requires-Python >=3.7.0,<3.11; 0.13.3 Requires-Python >=3.7.0,<3.11; 0.14.0 Requires-Python >=3.7.0,<3.11; 0.14.2 Requires-Python >=3.7.0,<3.11; 0.14.3 Requires-Python >=3.7.0,<3.11; 0.15.0 Requires-Python >=3.9.0,<3.12; 0.15.1 Requires-Python >=3.9.0,<3.12; 0.15.2 Requires-Python >=3.9.0,<3.12; 0.15.4 Requires-Python >=3.9.0,<3.12; 0.15.5 Requires-Python >=3.9.0,<3.12; 0.15.6 Requires-Python >=3.9.0,<3.12; 0.16.0 Requires-Python >=3.9.0,<3.12; 0.16.1 Requires-Python >=3.9.0,<3.12; 0.16.3 Requires-Python >=3.9.0,<3.12; 0.16.4 Requires-Python >=3.9.0,<3.12; 0.16.5 Requires-Python >=3.9.0,<3.12; 0.16.6 Requires-Python >=3.9.0,<3.12; 0.17.0 Requires-Python >=3.9.0,<3.12; 0.17.1 Requires-Python >=3.9.0,<3.12; 0.17.2 Requires-Python >=3.9.0,<3.12; 0.17.4 Requires-Python >=3.9.0,<3.12; 0.17.5 Requires-Python >=3.9.0,<3.12; 0.17.6 Requires-Python >=3.9.0,<3.12; 0.17.7 Requires-Python >=3.9.0,<3.12; 0.17.8 Requires-Python >=3.9.0,<3.12; 0.17.9 Requires-Python >=3.9.0,<3.12; 0.18.0 Requires-Python >=3.9.0,<3.12; 0.18.1 Requires-Python >=3.9.0,<3.12; 0.18.2 Requires-Python >=3.9.0,<3.12; 0.19.0 Requires-Python >=3.9.0,<3.12; 0.19.1 Requires-Python >=3.9.0,<3.12; 0.2.0 Requires-Python >=3.6.0,<3.10; 0.2.1 Requires-Python >=3.6.0,<3.10; 0.2.2 Requires-Python >=3.6.0,<3.10; 0.20.0 Requires-Python >=3.9.0,<3.12; 0.20.1 Requires-Python >=3.9.0,<3.12; 0.20.2 Requires-Python >=3.9.0,<3.12; 0.20.3 Requires-Python >=3.9.0,<3.12; 0.20.4 Requires-Python >=3.9.0,<3.12; 0.20.5 Requires-Python >=3.9.0,<3.12; 0.20.6 Requires-Python >=3.9.0,<3.12; 0.21.0 Requires-Python >=3.9.0,<3.12; 0.21.1 Requires-Python >=3.9.0,<3.12; 0.21.2 Requires-Python >=3.9.0,<3.12; 0.21.3 Requires-Python >=3.9.0,<3.12; 0.22.0 Requires-Python >=3.9.0,<3.12; 0.3.0 Requires-Python >=3.6.0,<3.10; 0.3.1 Requires-Python >=3.6.0,<3.10; 0.4.0 Requires-Python >=3.6.0,<3.10; 0.4.1 Requires-Python >=3.6.0,<3.10; 0.4.2 Requires-Python >=3.6.0,<3.10; 0.5.0 Requires-Python >=3.6.0,<3.10; 0.6.0 Requires-Python >=3.6.0,<3.10; 0.6.1 Requires-Python >=3.6.0,<3.10; 0.6.2 Requires-Python >=3.6.0,<3.10; 0.7.0 Requires-Python >=3.7.0,<3.11; 0.7.1 Requires-Python >=3.7.0,<3.11; 0.8.0 Requires-Python >=3.7.0,<3.11; 0.9.0 Requires-Python >=3.7.0,<3.11\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement TTS==0.22.0 (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for TTS==0.22.0\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# Install dependencies\n",
        "!pip install --upgrade pip\n",
        "!pip install -q TTS==0.22.0 torch tirchaudio librosa accelerate einops\n",
        "!pip install -q flask"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QtYfnyjnb1hw"
      },
      "source": [
        "## 2. Verify Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "L_LKScPNb1hw",
        "outputId": "fe43cbd9-9bcf-4a9c-83b0-d57d33375e5f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 16\n",
            "drwxr-xr-x 1 root root 4096 Nov 29 16:26 .\n",
            "drwxr-xr-x 1 root root 4096 Nov 29 16:25 ..\n",
            "drwxr-xr-x 4 root root 4096 Nov 20 14:30 .config\n",
            "drwxr-xr-x 1 root root 4096 Nov 20 14:30 sample_data\n"
          ]
        }
      ],
      "source": [
        "# List files\n",
        "!ls -la"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "5wMs0HjGb1hx",
        "outputId": "7cd3b9ea-8b29-4efc-d289-1178b1061e27",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "head: cannot open 'metadata_yor.csv' for reading: No such file or directory\n"
          ]
        }
      ],
      "source": [
        "# Check metadata file\n",
        "!head -5 metadata_yor.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M0_DwUJ2b1hx"
      },
      "source": [
        "## 3. Update Config for GPU Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "5XbsseW_b1hy",
        "outputId": "cf821cd0-2774-41e2-adc4-b535e15c5dd9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'train_vits.py'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-855356711.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Read the current train_vits.py\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train_vits.py'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mcontent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'train_vits.py'"
          ]
        }
      ],
      "source": [
        "# Update train_vits.py to use CUDA if available\n",
        "import os\n",
        "\n",
        "# Read the current train_vits.py\n",
        "with open('train_vits.py', 'r') as f:\n",
        "    content = f.read()\n",
        "\n",
        "# Replace use_cuda=False with use_cuda=True in the script if needed\n",
        "# (The Trainer should auto-detect GPU, but we can verify)\n",
        "print(\"train_vits.py is ready for training\")\n",
        "print(f\"CUDA available: {__import__('torch').cuda.is_available()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-7FkXrJb1hy"
      },
      "source": [
        "## 4. Start Training\n",
        "\n",
        "**Note:** Training will take several hours. You can monitor progress in the output below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YUf3sa5Gb1hy"
      },
      "outputs": [],
      "source": [
        "# Start training (this will run for a long time)\n",
        "!python train_vits.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3KABapK8b1hy"
      },
      "source": [
        "## 5. Monitor Training (Optional)\n",
        "\n",
        "You can check training logs and checkpoints while training is running."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q3yeqAfob1hz"
      },
      "outputs": [],
      "source": [
        "# List output directories\n",
        "!ls -lh out/naija_xtts_yor/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3vPOZ9Fkb1hz"
      },
      "outputs": [],
      "source": [
        "# View latest training log (update the directory name to match your run)\n",
        "!tail -50 out/naija_xtts_yor/*/trainer_0_log.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5sBtoy17b1hz"
      },
      "source": [
        "## 6. Test Inference\n",
        "\n",
        "After training (or using an existing checkpoint), test the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SZ8Iqc2sb1hz"
      },
      "outputs": [],
      "source": [
        "# Find the latest checkpoint\n",
        "import glob\n",
        "import os\n",
        "\n",
        "checkpoint_dirs = glob.glob('out/naija_xtts_yor/*/')\n",
        "if checkpoint_dirs:\n",
        "    latest_dir = max(checkpoint_dirs, key=os.path.getmtime)\n",
        "    checkpoints = glob.glob(os.path.join(latest_dir, 'checkpoint_*.pth'))\n",
        "    if checkpoints:\n",
        "        latest_checkpoint = max(checkpoints, key=os.path.getmtime)\n",
        "        print(f\"Latest checkpoint: {latest_checkpoint}\")\n",
        "    else:\n",
        "        print(\"No checkpoints found yet\")\n",
        "else:\n",
        "    print(\"No training runs found\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uxd1gV2xb1hz"
      },
      "outputs": [],
      "source": [
        "# Test synthesis\n",
        "from TTS.utils.synthesizer import Synthesizer\n",
        "from naija_formatter import naija_formatter\n",
        "import TTS.tts.datasets\n",
        "from IPython.display import Audio\n",
        "\n",
        "# Register formatter\n",
        "TTS.tts.datasets.naija = naija_formatter\n",
        "\n",
        "# Update these paths to match your latest checkpoint\n",
        "MODEL_PATH = latest_checkpoint  # Use the checkpoint found above\n",
        "CONFIG_PATH = os.path.join(os.path.dirname(latest_checkpoint), 'config.json')\n",
        "\n",
        "# Load model\n",
        "synthesizer = Synthesizer(\n",
        "    tts_checkpoint=MODEL_PATH,\n",
        "    tts_config_path=CONFIG_PATH,\n",
        "    use_cuda=True,  # Use GPU for inference\n",
        ")\n",
        "\n",
        "# Synthesize\n",
        "text = \"Bawo ni, se dada ni?\"\n",
        "print(f\"Synthesizing: {text}\")\n",
        "wav = synthesizer.tts(text)\n",
        "\n",
        "# Play audio\n",
        "Audio(wav, rate=synthesizer.output_sample_rate)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xryRHlcub1hz"
      },
      "source": [
        "## 7. Save Checkpoint to Google Drive (Optional)\n",
        "\n",
        "To preserve your trained model, save it to Google Drive."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ovkHlDqib1h0"
      },
      "outputs": [],
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R17wKoi8b1h0"
      },
      "outputs": [],
      "source": [
        "# Copy checkpoints to Drive\n",
        "!mkdir -p /content/drive/MyDrive/yoruba_tts_checkpoints\n",
        "!cp -r out/naija_xtts_yor/* /content/drive/MyDrive/yoruba_tts_checkpoints/\n",
        "print(\"Checkpoints saved to Google Drive!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4PWrV1a1b1h0"
      },
      "source": [
        "## 8. Run Web Interface (Optional)\n",
        "\n",
        "You can run the Flask web interface in Colab using ngrok for public access."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kb-qJ_M1b1h0"
      },
      "outputs": [],
      "source": [
        "# Install pyngrok\n",
        "!pip install -q pyngrok"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c7dbq5P_b1h0"
      },
      "outputs": [],
      "source": [
        "# Update app.py to use the latest checkpoint\n",
        "# Then start the Flask app with ngrok\n",
        "from pyngrok import ngrok\n",
        "import threading\n",
        "\n",
        "# Start Flask in background\n",
        "def run_flask():\n",
        "    os.system('python app.py')\n",
        "\n",
        "thread = threading.Thread(target=run_flask)\n",
        "thread.start()\n",
        "\n",
        "# Create ngrok tunnel\n",
        "public_url = ngrok.connect(5000)\n",
        "print(f\"\\nüåê Web Interface URL: {public_url}\")\n",
        "print(\"Click the link above to access your Yoruba TTS web interface!\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "runtime_attributes": {
        "runtime_version": "2025.07"
      }
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}